<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>JVM性能调优监控工具（转）</title>
      <link href="/2018/11/12/jvm-xing-neng-diao-you-jian-kong-gong-ju/"/>
      <url>/2018/11/12/jvm-xing-neng-diao-you-jian-kong-gong-ju/</url>
      
        <content type="html"><![CDATA[<p>现实企业级Java开发中，有时候我们会碰到下面这些问题：</p><ul><li><p>OutOfMemoryError，内存不足</p></li><li><p>内存泄露</p></li><li><p>线程死锁</p></li><li><p>锁争用（Lock Contention）</p></li><li><p>Java进程消耗CPU过高</p></li><li><p>……</p></li></ul><p>这些问题在日常开发中可能被很多人忽视（比如有的人遇到上面的问题只是重启服务器或者调大内存，而不会深究问题根源），但能够理解并解决这些问题是Java程序员进阶的必备要求。本文将对一些常用的JVM性能调优监控工具进行介绍，希望能起抛砖引玉之用。本文参考了网上很多资料，难以一一列举，在此对这些资料的作者表示感谢！关于JVM性能调优相关的资料，请参考文末。</p><p><strong>A、 jps(Java Virtual Machine Process Status Tool) </strong></p><p> jps主要用来输出JVM中运行的进程状态信息。语法格式如下：</p><pre><code> jps [options] [hostid]</code></pre><p>  如果不指定hostid就默认为当前主机或服务器。</p><p>  命令行参数选项说明如下：</p><pre><code>-q 不输出类名、Jar名和传入main方法的参数-m 输出传入main方法的参数-l 输出main类或Jar的全限名-v 输出传入JVM的参数</code></pre><p>  比如下面：</p><pre><code>root@ubuntu:/# jps -m -l2458 org.artifactory.standalone.main.Main /usr/local/artifactory-2.2.5/etc/jetty.xml29920 com.sun.tools.hat.Main -port 9998 /tmp/dump.dat3149 org.apache.catalina.startup.Bootstrap start30972 sun.tools.jps.Jps -m -l8247 org.apache.catalina.startup.Bootstrap start25687 com.sun.tools.hat.Main -port 9999 dump.dat21711 mrf-center.jar</code></pre><p><strong>B、 jstack</strong></p><p>jstack主要用来查看某个Java进程内的线程堆栈信息。语法格式如下：</p><pre><code>jstack [option] pidjstack [option] executable corejstack [option] [server-id@]remote-hostname-or-ip</code></pre><p>命令行参数选项说明如下：</p><pre><code>-l long listings，会打印出额外的锁信息，在发生死锁时可以用jstack -l pid来观察锁持有情况-m mixed mode，不仅会输出Java堆栈信息，还会输出C/C++堆栈信息（比如Native方法）</code></pre><p>jstack可以定位到线程堆栈，根据堆栈信息我们可以定位到具体代码，所以它在JVM性能调优中使用得非常多。下面我们来一个实例找出某个Java进程中最耗费CPU的Java线程并定位堆栈信息，用到的命令有ps、top、printf、jstack、grep。</p><p>第一步先找出Java进程ID，我部署在服务器上的Java应用名称为mrf-center：</p><pre><code>root@ubuntu:/# ps -ef | grep mrf-center | grep -v greproot     21711     1  1 14:47 pts/3    00:02:10 java -jar mrf-center.jar</code></pre><p>得到进程ID为21711，第二步找出该进程内最耗费CPU的线程，可以使用ps -Lfp pid或者ps -mp pid -o THREAD, tid, time或者top -Hp pid，我这里用第三个，输出如下：<br><img src="/images/pasted-13.png" alt="upload successful"></p><p>TIME列就是各个Java线程耗费的CPU时间，CPU时间最长的是线程ID为21742的线程，用</p><pre><code>printf &quot;%x\n&quot; 21742</code></pre><p>得到21742的十六进制值为54ee，下面会用到。    </p><p>OK，下一步终于轮到jstack上场了，它用来输出进程21711的堆栈信息，然后根据线程ID的十六进制值grep，如下：</p><pre><code>root@ubuntu:/# jstack 21711 | grep 54ee&quot;PollIntervalRetrySchedulerThread&quot; prio=10 tid=0x00007f950043e000 nid=0x54ee in Object.wait() [0x00007f94c6eda000]</code></pre><p>可以看到CPU消耗在PollIntervalRetrySchedulerThread这个类的Object.wait()，我找了下我的代码，定位到下面的代码：</p><pre><code>// Idle waitgetLog().info(&quot;Thread [&quot; + getName() + &quot;] is idle waiting...&quot;);schedulerThreadState = PollTaskSchedulerThreadState.IdleWaiting;long now = System.currentTimeMillis();long waitTime = now + getIdleWaitTime();long timeUntilContinue = waitTime - now;synchronized(sigLock) {    try {        if(!halted.get()) {            sigLock.wait(timeUntilContinue);        }    }     catch (InterruptedException ignore) {    }}</code></pre><p>它是轮询任务的空闲等待代码，上面的sigLock.wait(timeUntilContinue)就对应了前面的Object.wait()。</p><p><strong>C、 jmap（Memory Map）和jhat（Java Heap Analysis Tool）</strong></p><p>jmap用来查看堆内存使用状况，一般结合jhat使用。</p><p>jmap语法格式如下：</p><pre><code>jmap [option] pidjmap [option] executable corejmap [option] [server-id@]remote-hostname-or-ip</code></pre><p>如果运行在64位JVM上，可能需要指定-J-d64命令选项参数。</p><pre><code>jmap -permstat pid</code></pre><p>打印进程的类加载器和类加载器加载的持久代对象信息，输出：类加载器名称、对象是否存活（不可靠）、对象地址、父类加载器、已加载的类大小等信息，如下图：<br><img src="/images/pasted-14.png" alt="upload successful"></p><p>使用jmap -heap pid查看进程堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况。比如下面的例子：</p><pre><code>root@ubuntu:/# jmap -heap 21711Attaching to process ID 21711, please wait...Debugger attached successfully.Server compiler detected.JVM version is 20.10-b01using thread-local object allocation.Parallel GC with 4 thread(s)Heap Configuration:   MinHeapFreeRatio = 40   MaxHeapFreeRatio = 70   MaxHeapSize      = 2067791872 (1972.0MB)   NewSize          = 1310720 (1.25MB)   MaxNewSize       = 17592186044415 MB   OldSize          = 5439488 (5.1875MB)   NewRatio         = 2   SurvivorRatio    = 8   PermSize         = 21757952 (20.75MB)   MaxPermSize      = 85983232 (82.0MB)Heap Usage:PS Young GenerationEden Space:   capacity = 6422528 (6.125MB)   used     = 5445552 (5.1932830810546875MB)   free     = 976976 (0.9317169189453125MB)   84.78829520089286% usedFrom Space:   capacity = 131072 (0.125MB)   used     = 98304 (0.09375MB)   free     = 32768 (0.03125MB)   75.0% usedTo Space:   capacity = 131072 (0.125MB)   used     = 0 (0.0MB)   free     = 131072 (0.125MB)   0.0% usedPS Old Generation   capacity = 35258368 (33.625MB)   used     = 4119544 (3.9287033081054688MB)   free     = 31138824 (29.69629669189453MB)   11.683876009235595% usedPS Perm Generation   capacity = 52428800 (50.0MB)   used     = 26075168 (24.867218017578125MB)   free     = 26353632 (25.132781982421875MB)   49.73443603515625% used   ....</code></pre><p>使用jmap -histo[:live] pid查看堆内存中的对象数目、大小统计直方图，如果带上live则只统计活对象，如下：</p><pre><code>root@ubuntu:/# jmap -histo:live 21711 | more num     #instances         #bytes  class name----------------------------------------------   1:         38445        5597736  &lt;constMethodKlass&gt;   2:         38445        5237288  &lt;methodKlass&gt;   3:          3500        3749504  &lt;constantPoolKlass&gt;   4:         60858        3242600  &lt;symbolKlass&gt;   5:          3500        2715264  &lt;instanceKlassKlass&gt;   6:          2796        2131424  &lt;constantPoolCacheKlass&gt;   7:          5543        1317400  [I   8:         13714        1010768  [C   9:          4752        1003344  [B  10:          1225         639656  &lt;methodDataKlass&gt;  11:         14194         454208  java.lang.String  12:          3809         396136  java.lang.Class  13:          4979         311952  [S  14:          5598         287064  [[I  15:          3028         266464  java.lang.reflect.Method  16:           280         163520  &lt;objArrayKlassKlass&gt;  17:          4355         139360  java.util.HashMap$Entry  18:          1869         138568  [Ljava.util.HashMap$Entry;  19:          2443          97720  java.util.LinkedHashMap$Entry  20:          2072          82880  java.lang.ref.SoftReference  21:          1807          71528  [Ljava.lang.Object;  22:          2206          70592  java.lang.ref.WeakReference  23:           934          52304  java.util.LinkedHashMap  24:           871          48776  java.beans.MethodDescriptor  25:          1442          46144  java.util.concurrent.ConcurrentHashMap$HashEntry  26:           804          38592  java.util.HashMap  27:           948          37920  java.util.concurrent.ConcurrentHashMap$Segment  28:          1621          35696  [Ljava.lang.Class;  29:          1313          34880  [Ljava.lang.String;  30:          1396          33504  java.util.LinkedList$Entry  31:           462          33264  java.lang.reflect.Field  32:          1024          32768  java.util.Hashtable$Entry  33:           948          31440  [Ljava.util.concurrent.ConcurrentHashMap$HashEntry;</code></pre><p>class name是对象类型，说明如下：</p><pre><code>B  byteC  charD  doubleF  floatI  intJ  longZ  boolean[  数组，如[I表示int[][L+类名 其他对象</code></pre><p>还有一个很常用的情况是：用jmap把进程内存使用情况dump到文件中，再用jhat分析查看。jmap进行dump命令格式如下：</p><pre><code>jmap -dump:format=b,file=dumpFileName pid</code></pre><p>我一样地对上面进程ID为21711进行Dump：</p><pre><code>root@ubuntu:/# jmap -dump:format=b,file=/tmp/dump.dat 21711     Dumping heap to /tmp/dump.dat ...Heap dump file created</code></pre><p>dump出来的文件可以用MAT、VisualVM等工具查看，这里用jhat查看：</p><pre><code>root@ubuntu:/# jhat -port 9998 /tmp/dump.datReading from /tmp/dump.dat...Dump file created Tue Jan 28 17:46:14 CST 2014Snapshot read, resolving...Resolving 132207 objects...Chasing references, expect 26 dots..........................Eliminating duplicate references..........................Snapshot resolved.Started HTTP server on port 9998Server is ready.</code></pre><p>注意如果Dump文件太大，可能需要加上-J-Xmx512m这种参数指定最大堆内存，即jhat -J-Xmx512m -port 9998 /tmp/dump.dat。然后就可以在浏览器中输入主机地址:9998查看了：<br><img src="/images/pasted-15.png" alt="upload successful"></p><p>上面红线框出来的部分大家可以自己去摸索下，最后一项支持OQL（对象查询语言）。</p><p><strong>D、jstat（JVM统计监测工具）</strong></p><p>语法格式如下：</p><pre><code>jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ]</code></pre><p>vmid是Java虚拟机ID，在Linux/Unix系统上一般就是进程ID。interval是采样时间间隔。count是采样数目。比如下面输出的是GC信息，采样时间间隔为250ms，采样数为4：</p><pre><code>root@ubuntu:/# jstat -gc 21711 250 4 S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT   192.0  192.0   64.0   0.0    6144.0   1854.9   32000.0     4111.6   55296.0 25472.7    702    0.431   3      0.218    0.649192.0  192.0   64.0   0.0    6144.0   1972.2   32000.0     4111.6   55296.0 25472.7    702    0.431   3      0.218    0.649192.0  192.0   64.0   0.0    6144.0   1972.2   32000.0     4111.6   55296.0 25472.7    702    0.431   3      0.218    0.649192.0  192.0   64.0   0.0    6144.0   2109.7   32000.0     4111.6   55296.0 25472.7    702    0.431   3      0.218    0.649</code></pre><p>要明白上面各列的意义，先看JVM堆内存布局：<br><img src="/images/pasted-16.png" alt="upload successful"></p><p>可以看出：</p><pre><code>堆内存 = 年轻代 + 年老代 + 永久代年轻代 = Eden区 + 两个Survivor区（From和To）</code></pre><p>现在来解释各列含义：</p><pre><code>S0C、S1C、S0U、S1U：Survivor 0/1区容量（Capacity）和使用量（Used）EC、EU：Eden区容量和使用量OC、OU：年老代容量和使用量PC、PU：永久代容量和使用量YGC、YGT：年轻代GC次数和GC耗时FGC、FGCT：Full GC次数和Full GC耗时GCT：GC总耗时</code></pre><p><strong>E、hprof（Heap/CPU Profiling Tool）</strong></p><p>hprof能够展现CPU使用率，统计堆内存使用情况。</p><p>语法格式如下：</p><pre><code>java -agentlib:hprof[=options] ToBeProfiledClassjava -Xrunprof[:options] ToBeProfiledClassjavac -J-agentlib:hprof[=options] ToBeProfiledClass</code></pre><p>完整的命令选项如下：</p><pre><code>Option Name and Value  Description                    Default---------------------  -----------                    -------heap=dump|sites|all    heap profiling                 allcpu=samples|times|old  CPU usage                      offmonitor=y|n            monitor contention             nformat=a|b             text(txt) or binary output     afile=&lt;file&gt;            write data to file             java.hprof[.txt]net=&lt;host&gt;:&lt;port&gt;      send data over a socket        offdepth=&lt;size&gt;           stack trace depth              4interval=&lt;ms&gt;          sample interval in ms          10cutoff=&lt;value&gt;         output cutoff point            0.0001lineno=y|n             line number in traces?         ythread=y|n             thread in traces?              ndoe=y|n                dump on exit?                  ymsa=y|n                Solaris micro state accounting nforce=y|n              force output to &lt;file&gt;         yverbose=y|n            print messages about dumps     y</code></pre><p>来几个官方指南上的实例。</p><p>CPU Usage Sampling Profiling(cpu=samples)的例子：</p><pre><code>java -agentlib:hprof=cpu=samples,interval=20,depth=3 Hello</code></pre><p>上面每隔20毫秒采样CPU消耗信息，堆栈深度为3，生成的profile文件名称是java.hprof.txt，在当前目录。 </p><p>CPU Usage Times Profiling(cpu=times)的例子，它相对于CPU Usage Sampling Profile能够获得更加细粒度的CPU消耗信息，能够细到每个方法调用的开始和结束，它的实现使用了字节码注入技术（BCI）：</p><pre><code>javac -J-agentlib:hprof=cpu=times Hello.java</code></pre><p>Heap Allocation Profiling(heap=sites)的例子：</p><pre><code>javac -J-agentlib:hprof=heap=sites Hello.java</code></pre><p>Heap Dump(heap=dump)的例子，它比上面的Heap Allocation Profiling能生成更详细的Heap Dump信息：</p><pre><code>javac -J-agentlib:hprof=heap=dump Hello.java</code></pre><p>虽然在JVM启动参数中加入-Xrunprof:heap=sites参数可以生成CPU/Heap Profile文件，但对JVM性能影响非常大，不建议在线上服务器环境使用。</p>]]></content>
      
      
      <categories>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java多线程问题总结</title>
      <link href="/2018/11/08/java-duo-xian-cheng-wen-ti-zong-jie/"/>
      <url>/2018/11/08/java-duo-xian-cheng-wen-ti-zong-jie/</url>
      
        <content type="html"><![CDATA[<p>40个问题汇总</p><p>1、多线程有什么用？</p><p>一个可能在很多人看来很扯淡的一个问题：我会用多线程就好了，还管它有什么用？在我看来，这个回答更扯淡。所谓”知其然知其所以然”，”会用”只是”知其然”，”为什么用”才是”知其所以然”，只有达到”知其然知其所以然”的程度才可以说是把一个知识点运用自如。OK，下面说说我对这个问题的看法：</p><p>（1）发挥多核CPU的优势</p><p>随着工业的进步，现在的笔记本、台式机乃至商用的应用服务器至少也都是双核的，4核、8核甚至16核的也都不少见，如果是单线程的程序，那么在双核CPU上就浪费了50%，在4核CPU上就浪费了75%。单核CPU上所谓的”多线程”那是假的多线程，同一时间处理器只会处理一段逻辑，只不过线程之间切换得比较快，看着像多个线程”同时”运行罢了。多核CPU上的多线程才是真正的多线程，它能让你的多段逻辑同时工作，多线程，可以真正发挥出多核CPU的优势来，达到充分利用CPU的目的。</p><p>（2）防止阻塞</p><p>从程序运行效率的角度来看，单核CPU不但不会发挥出多线程的优势，反而会因为在单核CPU上运行多线程导致线程上下文的切换，而降低程序整体的效率。但是单核CPU我们还是要应用多线程，就是为了防止阻塞。试想，如果单核CPU使用单线程，那么只要这个线程阻塞了，比方说远程读取某个数据吧，对端迟迟未返回又没有设置超时时间，那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题，多条线程同时运行，哪怕一条线程的代码执行读取数据阻塞，也不会影响其它任务的执行。</p><p>（3）便于建模</p><p>这是另外一个没有这么明显的优点了。假设有一个大的任务A，单线程编程，那么就要考虑很多，建立整个程序模型比较麻烦。但是如果把这个大的任务A分解成几个小任务，任务B、任务C、任务D，分别建立程序模型，并通过多线程分别运行这几个任务，那就简单很多了。</p><p>2、创建线程的方式</p><p>比较常见的一个问题了，一般就是两种：</p><p>（1）继承Thread类</p><p>（2）实现Runnable接口</p><p>至于哪个好，不用说肯定是后者好，因为实现接口的方式比继承类的方式更灵活，也能减少程序之间的耦合度，面向接口编程也是设计模式6大原则的核心。</p><p>3、start()方法和run()方法的区别</p><p>只有调用了start()方法，才会表现出多线程的特性，不同线程的run()方法里面的代码交替执行。如果只是调用run()方法，那么代码还是同步执行的，必须等待一个线程的run()方法里面的代码全部执行完毕之后，另外一个线程才可以执行其run()方法里面的代码。</p><p>4、Runnable接口和Callable接口的区别</p><p>有点深的问题了，也看出一个Java程序员学习知识的广度。</p><p>Runnable接口中的run()方法的返回值是void，它做的事情只是纯粹地去执行run()方法中的代码而已；Callable接口中的call()方法是有返回值的，是一个泛型，和Future、FutureTask配合可以用来获取异步执行的结果。</p><p>这其实是很有用的一个特性，因为多线程相比单线程更难、更复杂的一个重要原因就是因为多线程充满着未知性，某条线程是否执行了？某条线程执行了多久？某条线程执行的时候我们期望的数据是否已经赋值完毕？无法得知，我们能做的只是等待这条多线程的任务执行完毕而已。而Callable+Future/FutureTask却可以获取多线程运行的结果，可以在等待时间太长没获取到需要的数据的情况下取消该线程的任务，真的是非常有用。</p><p>5、CyclicBarrier和CountDownLatch的区别</p><p>两个看上去有点像的类，都在java.util.concurrent下，都可以用来表示代码运行到某个点上，二者的区别在于：</p><p>（1）CyclicBarrier的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程继续运行</p><p>（2）CyclicBarrier只能唤起一个任务，CountDownLatch可以唤起多个任务</p><p>（3）CyclicBarrier可重用，CountDownLatch不可重用，计数值为0该CountDownLatch就不可再用了</p><p>6、volatile关键字的作用</p><p>一个非常重要的问题，是每个学习、应用多线程的Java程序员都必须掌握的。理解volatile关键字的作用的前提是要理解Java内存模型，这里就不讲Java内存模型了，可以参见第31点，volatile关键字的作用主要有两个：</p><p>（1）多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据</p><p>（2）代码底层执行不像我们看到的高级语言—-Java程序这么简单，它的执行是Java代码–&gt;字节码–&gt;根据字节码执行对应的C/C++代码–&gt;C/C++代码被编译成汇编语言–&gt;和硬件电路交互，现实中，为了获取更好的性能JVM可能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止语义重排序，当然这也一定程度上降低了代码执行效率</p><p>从实践角度而言，volatile的一个重要作用就是和CAS结合，保证了原子性，详细的可以参见java.util.concurrent.atomic包下的类，比如AtomicInteger。</p><p>7、什么是线程安全</p><p>又是一个理论的问题，各式各样的答案有很多，我给出一个个人认为解释地最好的：如果你的代码在多线程下执行和在单线程下执行永远都能获得一样的结果，那么你的代码就是线程安全的。</p><p>这个问题有值得一提的地方，就是线程安全也是有几个级别的：</p><p>（1）不可变</p><p>像String、Integer、Long这些，都是final类型的类，任何一个线程都改变不了它们的值，要改变除非新创建一个，因此这些不可变对象不需要任何同步手段就可以直接在多线程环境下使用</p><p>（2）绝对线程安全</p><p>不管运行时环境如何，调用者都不需要额外的同步措施。要做到这一点通常需要付出许多额外的代价，Java中标注自己是线程安全的类，实际上绝大多数都不是线程安全的，不过绝对线程安全的类，Java中也有，比方说CopyOnWriteArrayList、CopyOnWriteArraySet</p><p>（3）相对线程安全</p><p>相对线程安全也就是我们通常意义上所说的线程安全，像Vector这种，add、remove方法都是原子操作，不会被打断，但也仅限于此，如果有个线程在遍历某个Vector、有个线程同时在add这个Vector，99%的情况下都会出现ConcurrentModificationException，也就是fail-fast机制。</p><p>（4）线程非安全</p><p>这个就没什么好说的了，ArrayList、LinkedList、HashMap等都是线程非安全的类</p><p>8、Java中如何获取到线程dump文件</p><p>死循环、死锁、阻塞、页面打开慢等问题，打线程dump是最好的解决问题的途径。所谓线程dump也就是线程堆栈，获取到线程堆栈有两步：</p><p>（1）获取到线程的pid，可以通过使用jps命令，在Linux环境下还可以使用ps -ef | grep java</p><p>（2）打印线程堆栈，可以通过使用jstack pid命令，在Linux环境下还可以使用kill -3 pid</p><p>另外提一点，Thread类提供了一个getStackTrace()方法也可以用于获取线程堆栈。这是一个实例方法，因此此方法是和具体线程实例绑定的，每次获取获取到的是具体某个线程当前运行的堆栈，</p><p>9、一个线程如果出现了运行时异常会怎么样</p><p>如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放</p><p>10、如何在两个线程之间共享数据</p><p>通过在线程之间共享对象就可以了，然后通过wait/notify/notifyAll、await/signal/signalAll进行唤起和等待，比方说阻塞队列BlockingQueue就是为线程之间共享数据而设计的</p><p>11、sleep方法和wait方法有什么区别 </p><p>这个问题常问，sleep方法和wait方法都可以用来放弃CPU一定的时间，不同点在于如果线程持有某个对象的监视器，sleep方法不会放弃这个对象的监视器，wait方法会放弃这个对象的监视器</p><p>12、生产者消费者模型的作用是什么</p><p>这个问题很理论，但是很重要：</p><p>（1）通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率，这是生产者消费者模型最重要的作用</p><p>（2）解耦，这是生产者消费者模型附带的作用，解耦意味着生产者和消费者之间的联系少，联系越少越可以独自发展而不需要收到相互的制约</p><p>13、ThreadLocal有什么用</p><p>简单说ThreadLocal就是一种以空间换时间的做法，在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了</p><p>14、为什么wait()方法和notify()/notifyAll()方法要在同步块中被调用</p><p>这是JDK强制的，wait()方法和notify()/notifyAll()方法在调用前都必须先获得对象的锁</p><p>15、wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别</p><p>wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。</p><p>16、为什么要使用线程池</p><p>避免频繁地创建和销毁线程，达到线程对象的重用。另外，使用线程池还可以根据项目灵活地控制并发的数目。</p><p>17、怎么检测一个线程是否持有对象监视器</p><p>我也是在网上看到一道多线程面试题才知道有方法可以判断某个线程是否持有对象监视器：Thread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着”某条线程”指的是当前线程。</p><p>18、synchronized和ReentrantLock的区别</p><p>synchronized是和if、else、for、while一样的关键字，ReentrantLock是类，这是二者的本质区别。既然ReentrantLock是类，那么它就提供了比synchronized更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock比synchronized的扩展性体现在几点上：</p><p>（1）ReentrantLock可以对获取锁的等待时间进行设置，这样就避免了死锁</p><p>（2）ReentrantLock可以获取各种锁的信息</p><p>（3）ReentrantLock可以灵活地实现多路通知</p><p>另外，二者的锁机制其实也是不一样的。ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中mark word，这点我不能确定。</p><p>19、ConcurrentHashMap的并发度是什么</p><p>ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？</p><p>20、ReadWriteLock是什么</p><p>首先明确一下，不是说ReentrantLock不好，只是ReentrantLock某些时候有局限。如果使用ReentrantLock，可能本身是为了防止线程A在写数据、线程B在读数据造成的数据不一致，但这样，如果线程C在读数据、线程D也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。</p><p>因为这个，才诞生了读写锁ReadWriteLock。ReadWriteLock是一个读写锁接口，ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。</p><p>21、FutureTask是什么</p><p>这个其实前面有提到过，FutureTask表示一个异步运算的任务。FutureTask里面可以传入一个Callable的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。当然，由于FutureTask也是Runnable接口的实现类，所以FutureTask也可以放入线程池中。</p><p>22、Linux环境下如何查找哪个线程使用CPU最长</p><p>这是一个比较偏实践的问题，这种问题我觉得挺有意义的。可以这么做：</p><p>（1）获取项目的pid，jps或者ps -ef | grep java，这个前面有讲过</p><p>（2）top -H -p pid，顺序不能改变</p><p>这样就可以打印出当前的项目，每条线程占用CPU时间的百分比。注意这里打出的是LWP，也就是操作系统原生线程的线程号，我笔记本山没有部署Linux环境下的Java工程，因此没有办法截图演示，网友朋友们如果公司是使用Linux环境部署项目的话，可以尝试一下。</p><p>使用”top -H -p pid”+”jps pid”可以很容易地找到某条占用CPU高的线程的线程堆栈，从而定位占用CPU高的原因，一般是因为不当的代码操作导致了死循环。</p><p>最后提一点，”top -H -p pid”打出来的LWP是十进制的，”jps pid”打出来的本地线程号是十六进制的，转换一下，就能定位到占用CPU高的线程的当前线程堆栈了。</p><p>23、Java编程写一个会导致死锁的程序</p><p>第一次看到这个题目，觉得这是一个非常好的问题。很多人都知道死锁是怎么一回事儿：线程A和线程B相互等待对方持有的锁导致程序无限死循环下去。当然也仅限于此了，问一下怎么写一个死锁的程序就不知道了，这种情况说白了就是不懂什么是死锁，懂一个理论就完事儿了，实践中碰到死锁的问题基本上是看不出来的。</p><p>真正理解什么是死锁，这个问题其实不难，几个步骤：</p><p>（1）两个线程里面分别持有两个Object对象：lock1和lock2。这两个lock作为同步代码块的锁；</p><p>（2）线程1的run()方法中同步代码块先获取lock1的对象锁，Thread.sleep(xxx)，时间不需要太多，50毫秒差不多了，然后接着获取lock2的对象锁。这么做主要是为了防止线程1启动一下子就连续获得了lock1和lock2两个对象的对象锁</p><p>（3）线程2的run)(方法中同步代码块先获取lock2的对象锁，接着获取lock1的对象锁，当然这时lock1的对象锁已经被线程1锁持有，线程2肯定是要等待线程1释放lock1的对象锁的</p><p>这样，线程1”睡觉”睡完，线程2已经获取了lock2的对象锁了，线程1此时尝试获取lock2的对象锁，便被阻塞，此时一个死锁就形成了。代码就不写了，占的篇幅有点多，Java多线程7：死锁这篇文章里面有，就是上面步骤的代码实现。</p><p>24、怎么唤醒一个阻塞的线程</p><p>如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它；如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。</p><p>25、不可变对象对多线程有什么帮助</p><p>前面有提到过的一个问题，不可变对象保证了对象的内存可见性，对不可变对象的读取不需要进行额外的同步手段，提升了代码执行效率。</p><p>26、什么是多线程的上下文切换</p><p>多线程的上下文切换是指CPU控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取CPU执行权的线程的过程。</p><p>27、如果你提交任务时，线程池队列已满，这时会发生什么</p><p>这里区分一下：</p><p>如果使用的是无界队列LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为LinkedBlockingQueue可以近乎认为是一个无穷大的队列，可以无限存放任务<br>如果使用的是有界队列比如ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue中，ArrayBlockingQueue满了，会根据maximumPoolSize的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue继续满，那么则会使用拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy</p><p>28、Java中用到的线程调度算法是什么</p><p>抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。</p><p>29、Thread.sleep(0)的作用是什么</p><p>这个问题和上面那个问题是相关的，我就连在一起了。由于Java采用抢占式的线程调度算法，因此可能会出现某条线程常常获取到CPU控制权的情况，为了让某些优先级比较低的线程也能获取到CPU控制权，可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。</p><p>30、什么是自旋</p><p>很多synchronized里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然synchronized里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在synchronized的边界做忙循环，这就是自旋。如果做了多次忙循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。</p><p>31、什么是Java内存模型</p><p>Java内存模型定义了一种多线程访问Java内存的规范。Java内存模型要完整讲不是这里几句话能说清楚的，我简单总结一下Java内存模型的几部分内容：</p><p>（1）Java内存模型将内存分为了主内存和工作内存。类的状态，也就是类之间共享的变量，是存储在主内存中的，每次Java线程用到这些主内存中的变量的时候，会读一次主内存中的变量，并让这些内存在自己的工作内存中有一份拷贝，运行自己线程代码的时候，用到这些变量，操作的都是自己工作内存中的那一份。在线程代码执行完毕之后，会将最新的值更新到主内存中去</p><p>（2）定义了几个原子操作，用于操作主内存和工作内存中的变量</p><p>（3）定义了volatile变量的使用规则</p><p>（4）happens-before，即先行发生原则，定义了操作A必然先行发生于操作B的一些规则，比如在同一个线程内控制流前面的代码一定先行发生于控制流后面的代码、一个释放锁unlock的动作一定先行发生于后面对于同一个锁进行锁定lock的动作等等，只要符合这些规则，则不需要额外做同步措施，如果某段代码不符合所有的happens-before规则，则这段代码一定是线程非安全的</p><p>32、什么是CAS</p><p>CAS，全称为Compare and Swap，即比较-替换。假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功。</p><p>33、什么是乐观锁和悲观锁</p><p>（1）乐观锁：就像它的名字一样，对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。</p><p>（2）悲观锁：还是像它的名字一样，对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，不管三七二十一，直接上了锁就操作资源了。</p><p>34、什么是AQS</p><p>简单说一下AQS，AQS全称为AbstractQueuedSychronizer，翻译过来应该是抽象队列同步器。</p><p>如果说java.util.concurrent的基础是CAS的话，那么AQS就是整个Java并发包的核心了，ReentrantLock、CountDownLatch、Semaphore等等都用到了它。AQS实际上以双向队列的形式连接所有的Entry，比方说ReentrantLock，所有等待的线程都被放在一个Entry中并连成双向队列，前面一个线程使用ReentrantLock好了，则双向队列实际上的第一个Entry开始运行。</p><p>AQS定义了对双向队列所有的操作，而只开放了tryLock和tryRelease方法给开发者使用，开发者可以根据自己的实现重写tryLock和tryRelease方法，以实现自己的并发功能。</p><p>35、单例模式的线程安全性</p><p>老生常谈的问题了，首先要说的是单例模式的线程安全意味着：某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法，我总结一下：</p><p>（1）饿汉式单例模式的写法：线程安全</p><p>（2）懒汉式单例模式的写法：非线程安全</p><p>（3）双检锁单例模式的写法：线程安全</p><p>36、Semaphore有什么作用</p><p>Semaphore就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。</p><p>37、Hashtable的size()方法中明明只有一条语句”return count”，为什么还要做同步？</p><p>这是我之前的一个困惑，不知道大家有没有想过这个问题。某个方法中如果有多条语句，并且都在操作同一个类变量，那么在多线程环境下不加锁，势必会引发线程安全问题，这很好理解，但是size()方法明明只有一条语句，为什么还要加锁？</p><p>关于这个问题，在慢慢地工作、学习中，有了理解，主要原因有两点：</p><p>（1）同一时间只能有一条线程执行固定类的同步方法，但是对于类的非同步方法，可以多条线程同时访问。所以，这样就有问题了，可能线程A在执行Hashtable的put方法添加数据，线程B则可以正常调用size()方法读取Hashtable中当前元素的个数，那读取到的值可能不是最新的，可能线程A添加了完了数据，但是没有对size++，线程B就已经读取size了，那么对于线程B来说读取到的size一定是不准确的。而给size()方法加了同步之后，意味着线程B调用size()方法只有在线程A调用put方法完毕之后才可以调用，这样就保证了线程安全性</p><p>（2）CPU执行代码，执行的不是Java代码，这点很关键，一定得记住。Java代码最终是被翻译成机器码执行的，机器码才是真正可以和硬件电路交互的代码。即使你看到Java代码只有一行，甚至你看到Java代码编译之后生成的字节码也只有一行，也不意味着对于底层来说这句语句的操作只有一个。一句”return count”假设被翻译成了三句汇编语句执行，一句汇编语句和其机器码做对应，完全可能执行完第一句，线程就切换了。</p><p>38、线程类的构造方法、静态块是被哪个线程调用的</p><p>这是一个非常刁钻和狡猾的问题。请记住：线程类的构造方法、静态块是被new这个线程类所在的线程所调用的，而run方法里面的代码才是被线程自身所调用的。</p><p>如果说上面的说法让你感到困惑，那么我举个例子，假设Thread2中new了Thread1，main函数中new了Thread2，那么：</p><p>（1）Thread2的构造方法、静态块是main线程调用的，Thread2的run()方法是Thread2自己调用的</p><p>（2）Thread1的构造方法、静态块是Thread2调用的，Thread1的run()方法是Thread1自己调用的</p><p>39、同步方法和同步块，哪个是更好的选择</p><p>同步块，这意味着同步块之外的代码是异步执行的，这比同步整个方法更提升代码的效率。请知道一条原则：同步的范围越小越好。</p><p>借着这一条，我额外提一点，虽说同步的范围越少越好，但是在Java虚拟机中还是存在着一种叫做锁粗化的优化方法，这种方法就是把同步范围变大。这是有用的，比方说StringBuffer，它是一个线程安全的类，自然最常用的append()方法是一个同步方法，我们写代码的时候会反复append字符串，这意味着要进行反复的加锁-&gt;解锁，这对性能不利，因为这意味着Java虚拟机在这条线程上要反复地在内核态和用户态之间进行切换，因此Java虚拟机会将多次append方法调用的代码进行一个锁粗化的操作，将多次的append的操作扩展到append方法的头尾，变成一个大的同步块，这样就减少了加锁–&gt;解锁的次数，有效地提升了代码执行的效率。</p><p>40、高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？</p><p>这是我在并发编程网上看到的一个问题，把这个问题放在最后一个，希望每个人都能看到并且思考一下，因为这个问题非常好、非常实际、非常专业。关于这个问题，个人看法是：</p><p>（1）高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换</p><p>（2）并发不高、任务执行时间长的业务要区分开看：</p><p>　　a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以加大线程池中的线程数目，让CPU处理更多的业务</p><p>　　b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换</p><p>（3）并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考（2）。最后，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件对任务进行拆分和解耦。</p>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式系统数据一致性的6种方案(转)</title>
      <link href="/2018/06/09/fen-bu-shi-xi-tong-shu-ju-yi-zhi-xing-de-6-chong-fang-an-zhuan/"/>
      <url>/2018/06/09/fen-bu-shi-xi-tong-shu-ju-yi-zhi-xing-de-6-chong-fang-an-zhuan/</url>
      
        <content type="html"><![CDATA[<h4 id="问题的起源"><a href="#问题的起源" class="headerlink" title="问题的起源"></a>问题的起源</h4><p>在电商等业务中，系统一般由多个独立的服务组成，如何解决分布式调用时候数据的一致性？ </p><p>具体业务场景如下，比如一个业务操作，如果同时调用服务 A、B、C，需要满足要么同时成功；要么同时失败。A、B、C 可能是多个不同部门开发、部署在不同服务器上的远程服务。</p><p>在分布式系统来说，如果不想牺牲一致性，CAP 理论告诉我们只能放弃可用性，这显然不能接受。为了便于讨论问题，先简单介绍下数据一致性的基础理论。</p><h5 id="强一致"><a href="#强一致" class="headerlink" title="强一致"></a>强一致</h5><pre><code>当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要牺牲可用性。</code></pre><h5 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h5><pre><code>系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。</code></pre><h5 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h5><pre><code>弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS 是一个典型的最终一致性系统。</code></pre><p>在工程实践上，为了保障系统的可用性，互联网系统大多将强一致性需求转换成最终一致性的需求，并通过系统执行幂等性的保证，保证数据的最终一致性。但在电商等场景中，对于数据一致性的解决方法和常见的互联网系统（如 MySQL 主从同步）又有一定区别，群友的讨论分成以下 6 种解决方案。</p><h4 id="1-规避分布式事务——业务整合"><a href="#1-规避分布式事务——业务整合" class="headerlink" title="1. 规避分布式事务——业务整合"></a>1. 规避分布式事务——业务整合</h4><p>业务整合方案主要采用将接口整合到本地执行的方法。拿问题场景来说，则可以将服务 A、B、C 整合为一个服务 D 给业务，这个服务 D 再通过转换为本地事务的方式，比如服务 D 包含本地服务和服务 E，而服务 E 是本地服务 A ~ C 的整合。</p><p><strong>优点：</strong>解决（规避）了分布式事务。</p><p><strong>缺点：</strong>显而易见，把本来规划拆分好的业务，又耦合到了一起，业务职责不清晰，不利于维护。</p><p>由于这个方法存在明显缺点，通常不建议使用。</p><h4 id="2-经典方案-eBay-模式"><a href="#2-经典方案-eBay-模式" class="headerlink" title="2. 经典方案 - eBay 模式"></a>2. 经典方案 - eBay 模式</h4><p>此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。</p><p><strong>消息日志方案的核心是保证服务接口的幂等性。</strong></p><p>考虑到网络通讯失败、数据丢包等原因，如果接口不能保证幂等性，数据的唯一性将很难保证。</p><p>eBay 方式的主要思路如下。</p><p><strong>Base：一种 Acid 的替代方案</strong></p><p>此方案是 eBay 的架构师 Dan Pritchett 在 2008 年发表给 ACM 的文章，是一篇解释 BASE 原则，或者说最终一致性的经典文章。文中讨论了 BASE 与 ACID 原则在保证数据一致性的基本差异。</p><p>如果 ACID 为分区的数据库提供一致性的选择，那么如何实现可用性呢？答案是</p><p><strong>BASE (basically available, soft state, eventually consistent)</strong></p><p>BASE 的可用性是通过<strong>支持局部故障</strong>而不是系统全局故障来实现的。下面是一个简单的例子：如果将用户分区在 5 个数据库服务器上，BASE 设计鼓励类似的处理方式，一个用户数据库的故障只影响这台特定主机那 20% 的用户。这里不涉及任何魔法，不过它确实可以带来更高的可感知的系统可用性。</p><p>文章中描述了一个最常见的场景，如果产生了一笔交易，需要在交易表增加记录，同时还要修改用户表的金额。这两个表属于不同的远程服务，所以就涉及到分布式事务一致性的问题。<br><img src="/images/pasted-5.png" alt="upload successful"><br>文中提出了一个经典的解决方法，将主要修改操作以及更新用户表的消息<strong>放在一个本地事务</strong>来完成。同时为了避免重复消费用户表消息带来的问题，达到多次重试的幂等性，<strong>增加一个更新记录表 updates_applied</strong> 来记录已经处理过的消息。<br><img src="/images/pasted-6.png" alt="upload successful"><br>系统的执行伪代码如下<br><img src="/images/pasted-7.png" alt="upload successful"><br>基于以上方法，在第一阶段，通过本地的数据库的事务保障，增加了 transaction 表及消息队列 。</p><p>在第二阶段，分别读出消息队列（但不删除），通过判断更新记录表 updates_applied 来检测相关记录是否被执行，未被执行的记录会修改 user 表，然后增加一条操作记录到 updates_applied，事务执行成功之后再删除队列。</p><p>通过以上方法，达到了分布式系统的最终一致性。进一步了解 eBay 的方案可以参考文末链接。</p><h5 id="3-去哪儿网分布式事务方案"><a href="#3-去哪儿网分布式事务方案" class="headerlink" title="3. 去哪儿网分布式事务方案"></a>3. 去哪儿网分布式事务方案</h5><p>随着业务规模不断地扩大，电商网站一般都要面临拆分之路。就是将原来一个单体应用拆分成多个不同职责的子系统。比如以前可能将面向用户、客户和运营的功能都放在一个系统里，现在拆分为订单中心、代理商管理、运营系统、报价中心、库存管理等多个子系统。</p><p><strong>拆分首先要面临的是什么呢？</strong><br>最开始的单体应用所有功能都在一起，存储也在一起。比如运营要取消某个订单，那直接去更新订单表状态，然后更新库存表就 ok 了。因为是单体应用，库在一起，这些都可以在一个事务里，由关系数据库来保证一致性。</p><p>但拆分之后就不同了，不同的子系统都有自己的存储。比如订单中心就只管理自己的订单库，而库存管理也有自己的库。那么运营系统取消订单的时候就是通过接口调用等方式来调用订单中心和库存管理的服务了，而不是直接去操作库。这就涉及一个<strong>『分布式事务』</strong>的问题。</p><p>分布式事务有两种解决方式</p><p><strong>1. 优先使用异步消息。</strong><br>上文已经说过，使用异步消息 Consumer 端需要实现幂等。</p><p>幂等有两种方式，<strong>一种方式是业务逻辑保证幂等</strong>。比如接到支付成功的消息订单状态变成支付完成，如果当前状态是支付完成，则再收到一个支付成功的消息则说明消息重复了，直接作为消息成功处理。</p><p><strong>另外一种方式如果业务逻辑无法保证幂等，则要增加一个去重表或者类似的实现</strong>。对于 producer 端在业务数据库的同实例上放一个消息库，发消息和业务操作在同一个本地事务里。发消息的时候消息并不立即发出，而是向消息库插入一条消息记录，然后在事务提交的时候再异步将消息发出，发送消息如果成功则将消息库里的消息删除，如果遇到消息队列服务异常或网络问题，消息没有成功发出那么消息就留在这里了，会有另外一个服务不断地将这些消息扫出重新发送。</p><p><strong>2. 有的业务不适合异步消息的方式，事务的各个参与方都需要同步的得到结果。</strong><br>这种情况的实现方式其实和上面类似，每个参与方的本地业务库的同实例上面放一个事务记录库。</p><p>比如 A 同步调用 B，C。A 本地事务成功的时候更新本地事务记录状态，B 和 C 同样。如果有一次 A 调用 B 失败了，这个失败可能是 B 真的失败了，也可能是调用超时，实际 B 成功。则由一个中心服务对比三方的事务记录表，做一个最终决定。假设现在三方的事务记录是 A 成功，B 失败，C 成功。那么最终决定有两种方式，根据具体场景：</p><p>重试 B，直到 B 成功，事务记录表里记录了各项调用参数等信息；</p><p>执行 A 和 B 的补偿操作(一种可行的补偿方式是回滚)。</p><p>对 b 场景做一个特殊说明：比如 B 是扣库存服务，在第一次调用的时候因为某种原因失败了，但是重试的时候库存已经变为 0，无法重试成功，这个时候只有回滚 A 和 C 了。</p><p>那么可能有人觉得在业务库的同实例里放消息库或事务记录库，会对业务侵入，业务还要关心这个库，是否一个合理的设计？</p><p>实际上可以依靠运维的手段来简化开发的侵入，我们的方法是让 DBA 在公司所有 MySQL 实例上预初始化这个库，通过框架层（消息的客户端或事务 RPC 框架）透明的在背后操作这个库，业务开发人员只需要关心自己的业务逻辑，不需要直接访问这个库。</p><p>总结起来，其实两种方式的根本原理是类似的，也就是<strong>将分布式事务转换为多个本地事务，然后依靠重试等方式达到最终一致性。</strong></p><p><strong>4. 蘑菇街交易创建过程中的分布式一致性方案</strong>  </p><p><strong>交易创建的一般性流程</strong><br>我们把交易创建流程抽象出一系列可扩展的功能点，每个功能点都可以有多个实现（具体的实现之间有组合/互斥关系）。把各个功能点按照一定流程串起来，就完成了交易创建的过程。<br><img src="/images/pasted-8.png" alt="upload successful"><br><strong>面临的问题</strong><br>每个功能点的实现都可能会依赖外部服务。那么如何保证各个服务之间的数据是一致的呢？比如锁定优惠券服务调用超时了，不能确定到底有没有锁券成功，该如何处理？再比如锁券成功了，但是扣减库存失败了，该如何处理？<br><strong>方案选型</strong><br>服务依赖过多，会带来管理复杂性增加和稳定性风险增大的问题。试想如果我们强依赖 10 个服务，9 个都执行成功了，最后一个执行失败了，那么是不是前面 9 个都要回滚掉？这个成本还是非常高的。<br>所以在拆分大的流程为多个小的本地事务的前提下，对于非实时、非强一致性的关联业务写入，在本地事务执行成功后，我们选择发消息通知、关联事务异步化执行的方案。</p><p><strong>消息通知往往不能保证 100% 成功；且消息通知后，接收方业务是否能执行成功还是未知数。前者问题可以通过重试解决；后者可以选用事务消息来保证。</strong></p><p>但是事务消息框架本身会给业务代码带来侵入性和复杂性，所以我们选择<strong>基于 DB 事件变化通知到 MQ 的方式</strong>做系统间解耦，通过订阅方消费 MQ 消息时的 ACK 机制，保证消息一定消费成功，达到最终一致性。由于消息可能会被重发，消息订阅方业务逻辑处理要做好幂等保证。</p><p>所以目前只剩下需要实时同步做、有强一致性要求的业务场景了。在交易创建过程中，锁券和扣减库存是这样的两个典型场景。</p><p>要保证多个系统间数据一致，乍一看，必须要引入分布式事务框架才能解决。但引入非常重的类似二阶段提交分布式事务框架会带来复杂性的急剧上升；在电商领域，绝对的强一致是过于理想化的，我们可以选择准实时的最终一致性。</p><p>我们在交易创建流程中，<strong>首先创建一个不可见订单</strong>，然后在同步调用锁券和扣减库存时，针对调用异常（失败或者超时），发出废单消息到MQ。如果消息发送失败，本地会做时间阶梯式的异步重试；优惠券系统和库存系统收到消息后，会进行判断是否需要做业务回滚，这样就准实时地保证了多个本地事务的最终一致性。<br><img src="/images/pasted-9.png" alt="upload successful"></p><h5 id="5-支付宝及蚂蚁金融云的分布式服务-DTS-方案"><a href="#5-支付宝及蚂蚁金融云的分布式服务-DTS-方案" class="headerlink" title="5. 支付宝及蚂蚁金融云的分布式服务 DTS 方案"></a>5. 支付宝及蚂蚁金融云的分布式服务 DTS 方案</h5><p>业界常用的还有支付宝的一种 xts 方案，由支付宝在 2PC 的基础上改进而来。主要思路如下，大部分信息引用自官方网站。</p><p><strong>分布式事务服务简介</strong></p><p>分布式事务服务 (Distributed Transaction Service, DTS) 是一个分布式事务框架，用来保障在大规模分布式环境下事务的最终一致性。DTS 从架构上分为 xts-client 和 xts-server 两部分，前者是一个嵌入客户端应用的 JAR 包，主要负责事务数据的写入和处理；后者是一个独立的系统，主要负责异常事务的恢复。</p><p><strong>核心特性</strong></p><p>传统关系型数据库的事务模型必须遵守 ACID 原则。在单数据库模式下，ACID 模型能有效保障数据的完整性，但是在大规模分布式环境下，一个业务往往会跨越多个数据库，如何保证这多个数据库之间的数据一致性，需要其他行之有效的策略。在 JavaEE 规范中使用 2PC (2 Phase Commit, 两阶段提交) 来处理跨 DB 环境下的事务问题，但是 2PC 是反可伸缩模式，也就是说，在事务处理过程中，参与者需要一直持有资源直到整个分布式事务结束。这样，当业务规模达到千万级以上时，2PC 的局限性就越来越明显，系统可伸缩性会变得很差。基于此，我们采用 BASE 的思想实现了一套类似 2PC 的分布式事务方案，这就是 DTS。DTS在充分保障分布式环境下高可用性、高可靠性的同时兼顾数据一致性的要求，其最大的特点是保证数据最终一致 (Eventually consistent)。</p><p>简单的说，DTS 框架有如下特性：</p><p>最终一致：事务处理过程中，会有短暂不一致的情况，但通过恢复系统，可以让事务的数据达到最终一致的目标。</p><p>协议简单：DTS 定义了类似 2PC 的标准两阶段接口，业务系统只需要实现对应的接口就可以使用 DTS 的事务功能。</p><p>与 RPC 服务协议无关：在 SOA 架构下，一个或多个 DB 操作往往被包装成一个一个的 Service，Service 与 Service 之间通过 RPC 协议通信。DTS 框架构建在 SOA 架构上，与底层协议无关。</p><p>与底层事务实现无关： DTS 是一个抽象的基于 Service 层的概念，与底层事务实现无关，也就是说在 DTS 的范围内，无论是关系型数据库 MySQL，Oracle，还是 KV 存储 MemCache，或者列存数据库 HBase，只要将对其的操作包装成 DTS 的参与者，就可以接入到 DTS 事务范围内。</p><p>以下是分布式事务框架的流程图<br><img src="/images/pasted-10.png" alt="upload successful"></p><p><strong>实现</strong></p><p>一个完整的业务活动由一个主业务服务与若干从业务服务组成。<br>主业务服务负责发起并完成整个业务活动。<br>从业务服务提供 TCC 型业务操作。<br>业务活动管理器控制业务活动的一致性，它登记业务活动中的操作，并在活动提交时确认所有的两阶段事务的 confirm 操作，在业务活动取消时调用所有两阶段事务的 cancel 操作。”</p><p><strong>与 2PC 协议比较</strong></p><p>没有单独的 Prepare 阶段，降低协议成本<br>系统故障容忍度高，恢复简单</p><h5 id="6-农信网数据一致性方案"><a href="#6-农信网数据一致性方案" class="headerlink" title="6. 农信网数据一致性方案"></a>6. 农信网数据一致性方案</h5><p><strong>1. 电商业务</strong></p><p>公司的支付部门，通过接入其它第三方支付系统来提供支付服务给业务部门，支付服务是一个基于 Dubbo 的 RPC 服务。</p><p>对于业务部门来说，电商部门的订单支付，需要调用</p><p>支付平台的支付接口来处理订单；<br>同时需要调用积分中心的接口，按照业务规则，给用户增加积分。</p><p>从业务规则上需要同时保证业务数据的实时性和一致性，也就是支付成功必须加积分。</p><p>我们采用的方式是同步调用，首先处理本地事务业务。考虑到积分业务比较单一且业务影响低于支付，由积分平台提供增加与回撤接口。</p><p>具体的流程是先调用积分平台增加用户积分，再调用支付平台进行支付处理，如果处理失败，catch 方法调用积分平台的回撤方法，将本次处理的积分订单回撤。<br><img src="/images/pasted-11.png" alt="upload successful"></p><p><strong>2. 用户信息变更</strong></p><p>公司的用户信息，统一由用户中心维护，而用户信息的变更需要同步给各业务子系统，业务子系统再根据变更内容，处理各自业务。用户中心作为 MQ 的 producer，添加通知给 MQ。APP Server 订阅该消息，同步本地数据信息，再处理相关业务比如 APP 退出下线等。</p><p>我们采用异步消息通知机制，目前主要使用 ActiveMQ，基于 Virtual Topic 的订阅方式，保证单个业务集群订阅的单次消费。<br><img src="/images/pasted-12.png" alt="upload successful"></p><p><strong>总结</strong></p><p>分布式服务对衍生的配套系统要求比较多，特别是我们基于消息、日志的最终一致性方案，需要考虑消息的积压、消费情况、监控、报警等。</p><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><p><strong>Base: An Acid Alternative (eBay 方案)</strong><br>In partitioned databases, trading some consistency for availability can lead to dramatic improvements in scalability.<br><a href="http://queue.acm.org/detail.cfm?id=1394128" target="_blank" rel="noopener">http://queue.acm.org/detail.cfm?id=1394128</a> 英文版<br><a href="http://article.yeeyan.org/view/167444/125572" target="_blank" rel="noopener">http://article.yeeyan.org/view/167444/125572</a>  中文版</p><p><strong>分布式事务服务 (DTS) </strong><br><a href="https://www.cloud.alipay.com/docs/middleware/xts/index.html" target="_blank" rel="noopener">https://www.cloud.alipay.com/docs/middleware/xts/index.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>服务降级方案</title>
      <link href="/2018/06/08/fu-wu-jiang-ji-fang-an/"/>
      <url>/2018/06/08/fu-wu-jiang-ji-fang-an/</url>
      
        <content type="html"><![CDATA[<p>开发高并发系统时有三把利器用来保护系统：<strong>缓存、降级</strong>和<strong>限流</strong>。本文将详细聊聊降级。</p><p><strong>为什么需要降级：</strong>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。 </p><p><strong>降级的最终目：</strong>保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）</p><h4 id="降级预案"><a href="#降级预案" class="headerlink" title="降级预案"></a>降级预案</h4><p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：</p><p><strong>一般：</strong>比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p><p><strong>警告：</strong>有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p><p><strong>错误：</strong>比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</p><p><strong>严重错误：</strong>比如因为特殊原因数据错误了，此时需要紧急人工降级。</p><p>降级按照是否自动化可分为：<strong>自动开关降级</strong>和<strong>人工开关降级</strong>，按照功能可分为：<strong>读服务降级、写服务降级</strong>，按照处于的系统层次可分为：<strong>多级降级</strong>。</p><p>降级的功能点主要从服务端链路考虑，即根据用户访问的服务调用链路来梳理哪里需要降级：</p><p><strong>页面降级：</strong>在大促或者某些特殊情况下，某些页面占用了一些稀缺服务资源，在紧急情况下可以对其整个降级，以达到丢卒保帅；  </p><p><strong>页面片段降级：</strong>比如商品详情页中的商家部分因为数据错误了，此时需要对其进行降级；  </p><p><strong>页面异步请求降级：</strong>比如商品详情页上有推荐信息/配送至等异步加载的请求，如果这些信息响应慢或者后端服务有问题，可以进行降级； </p><p><strong>服务功能降级：</strong>比如渲染商品详情页时需要调用一些不太重要的服务：相 关分类、热销榜等，而这些服务在异常情况下直接不获取，即降级即可；  </p><p><strong>读降级：</strong>比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景；</p><p><strong>写降级：</strong>比如秒杀抢购，我们可以只进行Cache的更新，然后异步同步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。 </p><p><strong>爬虫降级：</strong>在大促活动时，可以将爬虫流量导向静态页或者返回空数据从而降级保护后端稀缺资源。 </p><p><strong>自动开关降级：</strong>自动降级是根据系统负载、资源使用情况、SLA等指标进行降级。  </p><p><strong>超时降级：</strong>当访问的数据库/http服务/远程调用响应慢或者长时间响应慢，且该服务不是核心服务的话可以在超时后自动降级；比如商品详情页上有推荐内容/评价，但是推荐内容/评价暂时不展示对用户购物流 程不会产生很大的影响； 对于这种服务是可以超时降级的。如果是调用别人的远程服务，和对方定义一个服务响应最大时间，如果超时了则自动降级。  </p><p><strong>统计失败次数降级：</strong>有时候依赖一些不稳定的API，比如调用外部机票服务，当失败调用次数达到一定阀值自动降级；然后通过异步线程去探测服务是否恢复了，则取消降级。  </p><p><strong>故障降级：</strong>比如要调用的远程服务挂掉了（网络故障、DNS故障、http服务返回错误的状态码、rpc服务抛出异常），则可以直接降级。降级后的处理方案有：默认值（比如库存服务挂了，返回默认现货）、兜底数据（比如广告挂了，返回提前准备好的一些静态页面）、缓存（之前暂存的一些缓存数据）。  </p><p><strong>限流降级：</strong>当我们去秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时开发者会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。  </p><p><strong>人工开关降级：</strong>在大促期间通过监控发现线上的一些服务存在问题，这个时候需要暂时将这些服务摘掉；还有有时候通过任务系统调用一些服务，但是服务依赖的数据库可能存在：网卡被打满了、挂掉了或者很多慢查询，此时需要暂停下任务系统让服务方进行处理；还有发现突然调用量太大，可能需要改变处理方式（比如同步转换为异步）；此时就可以使用开关来完成降级。</p><p>开关可以存放到配置文件、存放到数据库、存放到Redis/ZooKeeper；如果不是存放在本地，可以定期同步开关数据（比如1秒同步一次）。然后通过判断某个KEY的值来决定是否降级。</p><p>另外对于新开发的服务想上线进行灰度测试；但是不太确定该服务的逻辑是否正确，此时就需要设置开关，当新服务有问题可以通过开关切换回老服务。还有多机房服务，如果某个机房挂掉了，</p><p>此时需要将一个机房的服务切到另一个机房，此时也可以通过开关完成切换。</p><p>还有一些是因为功能问题需要暂时屏蔽掉某些功能，比如商品规格参数数据有问题，数据问题不能用回滚解决，此时需要开关控制降级。</p><p><strong>读服务降级：</strong>对于读服务降级一般采用的策略有：暂时切换读（降级到读缓存、降级到走静态化）、暂时屏蔽读（屏蔽读入口、屏蔽某个读服务）。在《应用多级缓存模式支撑海量读服务》中曾经介绍过读服务，<br>即接入层缓存–&gt;应用层本地缓存–&gt;分布式缓存–&gt;RPC服务/DB，我们会在接入层、应用层设置开关，当分布式缓存、RPC服务/DB有问题自动降级为不调用。当然这种情况适用于对读一致性要求不高的场景。</p><p>页面降级、页面片段降级、页面异步请求降级都是读服务降级，目的是丢卒保帅（比如因为这些服务也要使用核心资源、或者占了带宽影响到核心服务）或者因数据问题暂时屏蔽。</p><p>还有一种是页面静态化场景：</p><p><strong>动态化降级为静态化：</strong>比如平时网站可以走动态化渲染商品详情页，但是到了大促来临之际可以将其切换为静态化来减少对核心资源的占用，而且可以提升性能；其他还有如列表页、首页、频道页都可以这么玩；<br>可以通过一个程序定期的推送静态页到缓存或者生成到磁盘，出问题时直接切过去；</p><p><strong>静态化降级为动态化：</strong>比如当使用静态化来实现商品详情页架构时，平时使用静态化来提供服务，但是因为特殊原因静态化页面有问题了，需要暂时切换回动态化来保证服务正确性。</p><p>以上都保证出问题了有预案，用户还是可以使用网站，不影响用户购物。</p><p><strong>写服务降级：</strong>写服务在大多数场景下是不可降级的，不过可以通过一些迂回战术来解决问题。比如将同步操作转换为异步操作，或者限制写的量/比例。</p><p>比如扣减库存一般这样操作：</p><p><strong>方案1：</strong></p><p>1、扣减DB库存</p><p>2、扣减成功后更新Redis中的库存</p><p><strong>方案2：</strong></p><p>1、扣减Redis库存</p><p>2、同步扣减DB库存，如果扣减失败则回滚Redis库存；</p><p>前两种方案非常依赖DB，假设此时DB性能跟不上则扣减库存就会遇到问题；</p><p><strong>方案3：</strong></p><p>1、扣减Redis库存</p><p>2、正常同步扣减DB库存，性能扛不住时降级为发送一条扣减DB库存的消息，然后异步进行DB库存扣减实现最终一致即可；</p><p>这种方式发送扣减DB库存消息也可能成为瓶颈；这种情况我们可以考虑方案4</p><p><strong>方案4：</strong></p><p>1、扣减Redis库存</p><p>2、正常同步扣减DB库存，性能扛不住时降级为写扣减DB库存消息到本机，然后本机通过异步进行DB库存扣减来实现最终一致性。</p><p>也就是说正常情况可以同步扣减库存，在性能扛不住时降级为异步；另外如果是秒杀场景可以直接降级为异步，从而保护系统。还有如下单操作可以在大促时暂时降级将下单数据写入Redis，然后等峰值过去了再同步回DB，当然也有更好的解决方案，但是更复杂，不是本文的重点。</p><p>还有如用户评价，如果评价量太大，也可以把评价从同步写降级为异步写。当然也可以对评价按钮进行按比例开放（比如一些人的看不到评价操作按钮）。比如评价成功后会发一些奖励，在必要的时候降级同步到异步。</p><p><strong>多级降级：</strong>缓存是离用户最近越高效；而降级是离用户越近越能对系统保护的好。因为业务的复杂性导致越到后端QPS/TPS越低。</p><p><strong>页面JS降级开关：</strong>主要控制页面功能的降级，在页面中通过JS脚本部署功能降级开关，在适当时机开启/关闭开关；</p><p><strong>接入层降级开关：</strong>主要控制请求入口的降级，请求进入后会首先进入接入层，在接入层可以配置功能降级开关，可以根据实际情况进行自动/人工降级；这个可以参考《京东商品详情页服务闭环实践》，尤其在后端应用服务出问题时，通过接入层降级从而给应用服务有足够的时间恢复服务；</p><p><strong>应用层降级开关：</strong>主要控制业务的降级，在应用中配置相应的功能开关，根据实际业务情况进行自动/人工降级。</p><p><strong>某东《服务降级背后的技术架构设计》PPT内容</strong></p><p>牺牲部分用户体验</p><ul><li><p>商详页不显示特色服务icon、促销信息等</p></li><li><p>结算页不显示自提/311/411预约日历</p></li><li><p>订单详情页不显示GIS订单轨迹、催单等</p></li><li><p>评价列表禁止10页之后的翻页</p></li><li><p>实时统计和报表禁用</p></li><li><p>强制必选查询条件中的路由或索引字段</p></li><li><p>领豆豆防刷降级为拼图验证</p></li><li><p>H5变PC页面</p></li><li><p>使用通用内容代替个性化推荐内容</p></li></ul><p>　　降低安全级别</p><ul><li><p>发放京豆、提交订单、发表评论、登录不调用风控接口</p></li><li><p>结算页前端下单不启用验证码</p></li><li><p>集中式session不可用，cookie解密即可</p></li><li><p>ip limit服务，注册、登录不限制次数</p></li><li><p>商品修改内容不做敏感词过滤</p></li></ul><p>　　牺牲部分业务逻辑</p><ul><li><p>拍卖出价时不校验京豆数量</p></li><li><p>发表评价，不再校验是否退货</p></li></ul><p>　　延缓任务处理</p><ul><li><p>WMS任务处理引擎，暂停调拨、节能补贴等任务</p></li><li><p>OFW优先处理高优先级、拆分逻辑较简单的订单</p></li></ul><p>　　损失数据持久性</p><ul><li><p>用户地址更新，写redis，不回写数据库</p></li><li><p>库存预占，写redis，异步回写数据库</p></li><li><p>用户新增普票，写redis，不持久</p></li><li><p>订单二次拆分任务机制，由JMQ降为redis队列</p></li></ul><p>　　降低准确性/实时性</p><ul><li><p>实时价格过期不回源</p></li><li><p>动态页变静态拖底页</p></li><li><p>用户昵称接口降级，显示用户pin</p></li><li><p>库存状态接口降级，显示有货</p></li><li><p>抽奖异常，所有用户均显示未中奖</p></li></ul><p>　　降低性能</p><ul><li><p>数据库代替缓存防重、查询</p></li><li><p>数据库任务队列轮询代替MQ</p></li><li><p>CDN降为源站</p></li><li><p>本地缓存降为RPC</p></li></ul><p>　　降低容灾能力</p><ul><li><p>自动调度变为手工调度</p></li><li><p>VIP降级为real ip</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>服务溶断、降级、限流</title>
      <link href="/2018/06/08/fu-wu-rong-duan-jiang-ji-xian-liu/"/>
      <url>/2018/06/08/fu-wu-rong-duan-jiang-ji-xian-liu/</url>
      
        <content type="html"><![CDATA[<h5 id="服务熔断"><a href="#服务熔断" class="headerlink" title="服务熔断"></a>服务熔断</h5><p>在介绍熔断机制之前，我们需要了解微服务的雪崩效应。在微服务架构中，微服务是完成一个单一的业务功能，这样做的好处是可以做到解耦，每个微服务可以独立演进。但是，一个应用可能会有多个微服务组成，微服务之间的数据交互通过远程过程调用完成。这就带来一个问题，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。<br><img src="/images/pasted-0.png" alt="upload successful"><br>熔断机制是应对雪崩效应的一种微服务链路保护机制。我们在各种场景下都会接触到熔断这两个字。高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。股票交易中，如果股票指数过高，也会采用熔断机制，暂停股票的交易。同样，在微服务架构中，熔断机制也是起着类似的作用。当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。</p><p>在Spring Cloud框架里，熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。</p><p>在dubbo中也可利用nio超时+失败次数做熔断。<br>dubbo可以通过扩展Filter的方式引入Hystrix，具体代码如下：</p><pre class=" language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>netease<span class="token punctuation">.</span>hystrix<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>filter<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>common<span class="token punctuation">.</span>Constants<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>common<span class="token punctuation">.</span>extension<span class="token punctuation">.</span>Activate<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>Filter<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>Invocation<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>Invoker<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>Result<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>RpcException<span class="token punctuation">;</span><span class="token annotation punctuation">@Activate</span><span class="token punctuation">(</span>group <span class="token operator">=</span> Constants<span class="token punctuation">.</span>CONSUMER<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HystrixFilter</span> <span class="token keyword">implements</span> <span class="token class-name">Filter</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> Result <span class="token function">invoke</span><span class="token punctuation">(</span>Invoker invoker<span class="token punctuation">,</span> Invocation invocation<span class="token punctuation">)</span> <span class="token keyword">throws</span> RpcException <span class="token punctuation">{</span>DubboHystrixCommand command <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">DubboHystrixCommand</span><span class="token punctuation">(</span>invoker<span class="token punctuation">,</span> invocation<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">return</span> command<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">}</span>DubboHystrixCommand<span class="token keyword">package</span> com<span class="token punctuation">.</span>netease<span class="token punctuation">.</span>hystrix<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>filter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span>Logger<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>common<span class="token punctuation">.</span>URL<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>Invocation<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>Invoker<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>dubbo<span class="token punctuation">.</span>rpc<span class="token punctuation">.</span>Result<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>netflix<span class="token punctuation">.</span>hystrix<span class="token punctuation">.</span>HystrixCommand<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>netflix<span class="token punctuation">.</span>hystrix<span class="token punctuation">.</span>HystrixCommandGroupKey<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>netflix<span class="token punctuation">.</span>hystrix<span class="token punctuation">.</span>HystrixCommandKey<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>netflix<span class="token punctuation">.</span>hystrix<span class="token punctuation">.</span>HystrixCommandProperties<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>netflix<span class="token punctuation">.</span>hystrix<span class="token punctuation">.</span>HystrixThreadPoolProperties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">DubboHystrixCommand</span> <span class="token keyword">extends</span> <span class="token class-name">HystrixCommand</span> <span class="token punctuation">{</span><span class="token keyword">private</span> <span class="token keyword">static</span> Logger logger <span class="token operator">=</span> Logger<span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span>DubboHystrixCommand<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> DEFAULT_THREADPOOL_CORE_SIZE <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">;</span><span class="token keyword">private</span> Invoker invoker<span class="token punctuation">;</span><span class="token keyword">private</span> Invocation invocation<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token function">DubboHystrixCommand</span><span class="token punctuation">(</span>Invoker invoker<span class="token punctuation">,</span>Invocation invocation<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token keyword">super</span><span class="token punctuation">(</span>Setter<span class="token punctuation">.</span><span class="token function">withGroupKey</span><span class="token punctuation">(</span>HystrixCommandGroupKey<span class="token punctuation">.</span>Factory<span class="token punctuation">.</span><span class="token function">asKey</span><span class="token punctuation">(</span>invoker<span class="token punctuation">.</span><span class="token function">getInterface</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">andCommandKey</span><span class="token punctuation">(</span>HystrixCommandKey<span class="token punctuation">.</span>Factory<span class="token punctuation">.</span><span class="token function">asKey</span><span class="token punctuation">(</span>String<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"%s_%d"</span><span class="token punctuation">,</span> invocation<span class="token punctuation">.</span><span class="token function">getMethodName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>invocation<span class="token punctuation">.</span><span class="token function">getArguments</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> null <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> invocation<span class="token punctuation">.</span><span class="token function">getArguments</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">andCommandPropertiesDefaults</span><span class="token punctuation">(</span>HystrixCommandProperties<span class="token punctuation">.</span><span class="token function">Setter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">withCircuitBreakerRequestVolumeThreshold</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//10秒钟内至少19此请求失败，熔断器才发挥起作用</span><span class="token punctuation">.</span><span class="token function">withCircuitBreakerSleepWindowInMilliseconds</span><span class="token punctuation">(</span><span class="token number">30000</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//熔断器中断请求30秒后会进入半打开状态,放部分流量过去重试</span><span class="token punctuation">.</span><span class="token function">withCircuitBreakerErrorThresholdPercentage</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//错误率达到50开启熔断保护</span><span class="token punctuation">.</span><span class="token function">withExecutionTimeoutEnabled</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//使用dubbo的超时，禁用这里的超时</span><span class="token punctuation">.</span><span class="token function">andThreadPoolPropertiesDefaults</span><span class="token punctuation">(</span>HystrixThreadPoolProperties<span class="token punctuation">.</span><span class="token function">Setter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">withCoreSize</span><span class="token punctuation">(</span><span class="token function">getThreadPoolCoreSize</span><span class="token punctuation">(</span>invoker<span class="token punctuation">.</span><span class="token function">getUrl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//线程池为30</span><span class="token keyword">this</span><span class="token punctuation">.</span>invoker<span class="token operator">=</span>invoker<span class="token punctuation">;</span><span class="token keyword">this</span><span class="token punctuation">.</span>invocation<span class="token operator">=</span>invocation<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">/*** 获取线程池大小** @param url* @return*/</span><span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">getThreadPoolCoreSize</span><span class="token punctuation">(</span>URL url<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token keyword">if</span> <span class="token punctuation">(</span>url <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token keyword">int</span> size <span class="token operator">=</span> url<span class="token punctuation">.</span><span class="token function">getParameter</span><span class="token punctuation">(</span><span class="token string">"ThreadPoolCoreSize"</span><span class="token punctuation">,</span> DEFAULT_THREADPOOL_CORE_SIZE<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>logger<span class="token punctuation">.</span><span class="token function">isDebugEnabled</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>logger<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span><span class="token string">"ThreadPoolCoreSize:"</span> <span class="token operator">+</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">return</span> size<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">return</span> DEFAULT_THREADPOOL_CORE_SIZE<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token annotation punctuation">@Override</span><span class="token keyword">protected</span> Result <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span><span class="token keyword">return</span> invoker<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>invocation<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>线程池大小可以通过dubbo参数进行控制，当前其他的参数也可以通过类似的方式进行配置</p><p>代码添加好后在，resource添加加载文本</p><p>|-resources<br>|-META-INF<br>|-dubbo<br>|-com.alibaba.dubbo.rpc.Filter (纯文本文件，内容为：hystrix=com.netease.hystrix.dubbo.rpc.filter.HystrixFilter</p><p>由于Filter定义为自动激活的，所以启动代码所有消费者都被隔离起来啦！</p><p>熔段解决如下几个问题：<br>    当所依赖的对象不稳定时，能够起到快速失败的目的<br>    快速失败后，能够根据一定的算法动态试探所依赖对象是否恢复</p><p>参考：<br><a href="http://www.roncoo.com/article/detail/126834" target="_blank" rel="noopener">http://www.roncoo.com/article/detail/126834</a><br><a href="https://www.cnblogs.com/lvgg/p/7843809.html" target="_blank" rel="noopener">https://www.cnblogs.com/lvgg/p/7843809.html</a>   </p><h5 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h5><p>降级是指自己的待遇下降了，从RPC调用环节来讲，就是去访问一个本地的伪装者而不是真实的服务。</p><pre><code>当双11活动时，把无关交易的服务统统降级，如查看蚂蚁深林，查看历史订单，商品历史评论，只显示最后100条等等。</code></pre><h5 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h5><p>相同点：<br>目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段；<br>最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用；<br>粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）；<br>自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段；</p><p>区别：<br>触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；<br>管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）<br>实现方式不太一样；服务降级具有代码侵入性(由控制器完成/或自动降级)，熔断一般称为自我熔断。</p><h5 id="服务限流"><a href="#服务限流" class="headerlink" title="服务限流"></a>服务限流</h5><p>在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流。缓存的目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹；而降级是当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询（评论的最后几页），因此需有一种手段来限制这些场景的并发/请求量，即限流。</p><p>限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）。</p><p>一般开发高并发系统常见的限流有：限制总并发数（比如数据库连接池、线程池）、限制瞬时并发数（如nginx的limit_conn模块，用来限制瞬时并发连接数）、限制时间窗口内的平均速率（如Guava的RateLimiter、nginx的limit_req模块，限制每秒的平均速率）；其他还有如限制远程接口调用速率、限制MQ的消费速率。另外还可以根据网络连接数、网络流量、CPU或内存负载等来限流。</p><h5 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h5><p>常见的限流算法有：令牌桶、漏桶。计数器也可以进行粗暴限流实现。</p><p>漏桶(Leaky Bucket)算法思路很简单,水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求,可以看出漏桶算法能强行限制数据的传输速率.示意图如下:<br><img src="/images/pasted-1.png" alt="upload successful"></p><p>令牌桶算法(Token Bucket)和 Leaky Bucket 效果一样但方向相反的算法,更加容易理解.随着时间流逝,系统会按恒定1/QPS时间间隔(如果QPS=100,则间隔是10ms)往桶里加入Token(想象和漏洞漏水相反,有个水龙头在不断的加水),如果桶已经满了就不再加了.新请求来临时,会各自拿走一个Token,如果没有Token可拿了就阻塞或者拒绝服务.<br><img src="/images/pasted-2.png" alt="upload successful"><br>令牌桶的另外一个好处是可以方便的改变速度. 一旦需要提高速率,则按需提高放入桶中的令牌的速率. 一般会定时(比如100毫秒)往桶中增加一定数量的令牌, 有些变种算法则实时的计算应该增加的令牌的数量.</p><h5 id="应用级限流"><a href="#应用级限流" class="headerlink" title="应用级限流"></a>应用级限流</h5><p>对于一个应用系统来说一定会有极限并发/请求数，即总有一个TPS/QPS阀值，如果超了阀值则系统就会不响应用户请求或响应的非常慢，因此我们最好进行过载保护，防止大量请求涌入击垮系统。</p><p>如果你使用过Tomcat，其Connector其中一种配置有如下几个参数：<br>acceptCount：如果Tomcat的线程都忙于响应，新来的连接会进入队列排队，如果超出排队大小，则拒绝连接；</p><p>maxConnections：瞬时最大连接数，超出的会排队等待；</p><p>maxThreads：Tomcat能启动用来处理请求的最大线程数，如果请求处理量一直远远大于最大线程数则可能会僵死。</p><p>详细的配置请参考官方文档。另外如MySQL（如max_connections）、Redis（如tcp-backlog）都会有类似的限制连接数的配置。</p><h5 id="池化技术"><a href="#池化技术" class="headerlink" title="池化技术"></a>池化技术</h5><p>如果有的资源是稀缺资源（如数据库连接、线程），而且可能有多个系统都会去使用它，那么需要限制应用；可以使用池化技术来限制总资源数：连接池、线程池。比如分配给每个应用的数据库连接是100，那么本应用最多可以使用100个资源，超出了可以等待或者抛异常。<br>限流某个接口的总并发/请求数</p><p>如果接口可能会有突发访问情况，但又担心访问量太大造成崩溃，如抢购业务；这个时候就需要限制这个接口的总并发/请求数总请求数了；因为粒度比较细，可以为每个接口都设置相应的阀值。可以使用Java中的AtomicLong进行限流：</p><pre class=" language-java"><code class="language-java"><span class="token keyword">try</span> <span class="token punctuation">{</span><span class="token keyword">if</span><span class="token punctuation">(</span>atomic<span class="token punctuation">.</span><span class="token function">incrementAndGet</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> 限流数<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment" spellcheck="true">//拒绝请求</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">//处理请求</span><span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>atomic<span class="token punctuation">.</span><span class="token function">decrementAndGet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>参考：<br><a href="https://blog.csdn.net/g_hongjin/article/details/51649246" target="_blank" rel="noopener">https://blog.csdn.net/g_hongjin/article/details/51649246</a></p><h5 id="分布式限流"><a href="#分布式限流" class="headerlink" title="分布式限流"></a>分布式限流</h5><p>分布式限流最关键的是要将限流服务做成原子化，而解决方案可以使使用redis+lua或者nginx+lua技术进行实现，通过这两种技术可以实现的高并发和高性能。</p><p>首先我们来使用redis+lua实现时间窗内某个接口的请求数限流，实现了该功能后可以改造为限流总并发/请求数和限制总资源数。Lua本身就是一种编程语言，也可以使用它实现复杂的令牌桶或漏桶算法。</p><p>有人会纠结如果应用并发量非常大那么redis或者nginx是不是能抗得住；不过这个问题要从多方面考虑：你的流量是不是真的有这么大，是不是可以通过一致性哈希将分布式限流进行分片，是不是可以当并发量太大降级为应用级限流；对策非常多，可以根据实际情况调节；像在京东使用Redis+Lua来限流抢购流量，一般流量是没有问题的。</p><p>对于分布式限流目前遇到的场景是业务上的限流，而不是流量入口的限流；流量入口限流应该在接入层完成，而接入层笔者一般使用Nginx。</p><h5 id="基于Redis功能的实现限流"><a href="#基于Redis功能的实现限流" class="headerlink" title="基于Redis功能的实现限流"></a>基于Redis功能的实现限流</h5><p>参考：<br><a href="https://www.cnblogs.com/exceptioneye/p/4783904.html" target="_blank" rel="noopener">https://www.cnblogs.com/exceptioneye/p/4783904.html</a><br>简陋的设计思路：假设一个用户（用IP判断）每分钟访问某一个服务接口的次数不能超过10次，那么我们可以在Redis中创建一个键，并此时我们就设置键的过期时间为60秒，<strong>每一个用户对此服务接口的访问就把键值加1，在60秒内当键值增加到10的时候，就禁止访问服务接口。</strong>在某种场景中添加访问时间间隔还是很有必要的。</p><h5 id="基于令牌桶算法的实现"><a href="#基于令牌桶算法的实现" class="headerlink" title="基于令牌桶算法的实现"></a>基于令牌桶算法的实现</h5><p>令牌桶算法最初来源于计算机网络。在网络传输数据时，为了防止网络拥塞，需限制流出网络的流量，使流量以比较均匀的速度向外发送。令牌桶算法就实现了这个功能，可控制发送到网络上数据的数目，并允许突发数据的发送。</p><p>令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。</p><p>大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌。如果令牌不被消耗，或者被消耗的速度小于产生的速度，令牌就会不断地增多，直到把桶填满。后面再产生的令牌就会从桶中溢出。最后桶中可以保存的最大令牌数永远不会超过桶的大小。</p><p>传送到令牌桶的数据包需要消耗令牌。不同大小的数据包，消耗的令牌数量不一样。</p><p>令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。</p><p><img src="/images/pasted-3.png" alt="upload successful"></p><p>算法描述：</p><p>假如用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶中（每秒会有r个令牌放入桶中）；</p><p>假设桶中最多可以存放b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃；</p><p>当一个n个字节的数据包到达时，就从令牌桶中删除n个令牌（不同大小的数据包，消耗的令牌数量不一样），并且数据包被发送到网络；</p><p>如果令牌桶中少于n个令牌，那么不会删除令牌，并且认为这个数据包在流量限制之外（n个字节，需要n个令牌。该数据包将被缓存或丢弃）；</p><p>算法允许最长b个字节的突发，但从长期运行结果看，数据包的速率被限制成常量r。对于在流量限制外的数据包可以以不同的方式处理：（1）它们可以被丢弃；（2）它们可以排放在队列中以便当令牌桶中累积了足够多的令牌时再传输；（3）它们可以继续发送，但需要做特殊标记，网络过载的时候将这些特殊标记的包丢弃。</p><p>Java实现</p><p>我们可以使用Guava 的 RateLimiter 来实现基于令牌桶的流控，RateLimiter 令牌桶算法是单桶实现。RateLimiter 对简单的令牌桶算法做了一些工程上的优化，具体的实现是 SmoothBursty。需要注意的是，RateLimiter 的另一个实现SmoothWarmingUp，就不是令牌桶了，而是漏桶算法。也许是出于简单起见，RateLimiter 中的时间窗口能且仅能为 1s。</p><p>SmoothBursty 有一个可以放 N 个时间窗口产生的令牌的桶，系统空闲的时候令牌就一直攒着，最好情况下可以扛 N 倍于限流值的高峰而不影响后续请求。RateLimite允许某次请求拿走超出剩余令牌数的令牌，但是下一次请求将为此付出代价，一直等到令牌亏空补上，并且桶中有足够本次请求使用的令牌为止。当某次请求不能得到所需要的令牌时，这时涉及到一个权衡，是让前一次请求干等到令牌够用才走掉呢，还是让它先走掉后面的请求等一等呢？Guava 的设计者选择的是后者，先把眼前的活干了，后面的事后面再说。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2016/08/01/hello-world/"/>
      <url>/2016/08/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
  
  
</search>
